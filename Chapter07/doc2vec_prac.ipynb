{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin-/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import string\n",
    "import requests\n",
    "import collections\n",
    "import io\n",
    "import tarfile\n",
    "import urllib.request\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.getcwd() + '/Chapter07')\n",
    "import text_helpers\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-89f5509112d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "ops.reset_default_graph()\n",
    "# os.chdir(os.path.dirname(os.path.realpath(__file__)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_name = os.getcwd() + '/Chapter07/temp/'\n",
    "if not os.path.exists(data_folder_name):\n",
    "    os.makedirs(data_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a graph session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Declare model parameters\n",
    "batch_size = 500\n",
    "vocabulary_size = 7500\n",
    "generations = 100000\n",
    "model_learning_rate = 0.001\n",
    "\n",
    "embedding_size = 200   # Word embedding size\n",
    "doc_embedding_size = 100   # Document embedding size\n",
    "concatenated_size = embedding_size + doc_embedding_size\n",
    "\n",
    "num_sampled = int(batch_size/2)    # Number of negative examples to sample.\n",
    "window_size = 3       # How many words to consider to the left.\n",
    "\n",
    "# Add checkpoints to training\n",
    "save_embeddings_every = 5000\n",
    "print_valid_every = 5000\n",
    "print_loss_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./temp/df_180807.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "Compressed file ended before the end-of-stream marker was reached",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-7aa8a1342c2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the movie review data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading Data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_helpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_movie_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_folder_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/TensorFlow-Machine-Learning-Cookbook/Chapter07/text_helpers.py\u001b[0m in \u001b[0;36mload_movie_data\u001b[0;34m(data_folder_name)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mtar_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r:gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtar_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rt-polaritydata/rt-polarity.pos'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0mneg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtar_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rt-polaritydata/rt-polarity.neg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;31m# Save pos/neg reviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36mextractfile\u001b[0;34m(self, member)\u001b[0m\n\u001b[1;32m   2072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2073\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2074\u001b[0;31m             \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2075\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2076\u001b[0m             \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmember\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36mgetmember\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1746\u001b[0m            \u001b[0mmost\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdate\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \"\"\"\n\u001b[0;32m-> 1748\u001b[0;31m         \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getmember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1749\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filename %r not found\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36m_getmember\u001b[0;34m(self, name, tarinfo, normalize)\u001b[0m\n\u001b[1;32m   2331\u001b[0m         \"\"\"\n\u001b[1;32m   2332\u001b[0m         \u001b[0;31m# Ensure that all members have been loaded.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2333\u001b[0;31m         \u001b[0mmembers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmembers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2335\u001b[0m         \u001b[0;31m# Limit the member search list up to tarinfo.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36mgetmembers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loaded\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# if we want to obtain a list of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# all members, we first have to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m                                 \u001b[0;31m# scan the whole archive.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmembers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2354\u001b[0m         \"\"\"\n\u001b[1;32m   2355\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2356\u001b[0;31m             \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2357\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2285\u001b[0m         \u001b[0;31m# Advance the file pointer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2286\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2287\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2288\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2289\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mReadError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unexpected end of data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mseek\u001b[0;34m(self, offset, whence)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREAD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_not_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/_compression.py\u001b[0m in \u001b[0;36mseek\u001b[0;34m(self, offset, whence)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# Read and discard data until we reach the desired position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    480\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m                 raise EOFError(\"Compressed file ended before the \"\n\u001b[0m\u001b[1;32m    483\u001b[0m                                \"end-of-stream marker was reached\")\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Compressed file ended before the end-of-stream marker was reached"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# # Load the movie review data\n",
    "# print('Loading Data')\n",
    "# texts, target = text_helpers.load_movie_data(data_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_data = []\n",
    "with open('/home/admin-/PycharmProjects/TensorFlow-Machine-Learning-Cookbook/Chapter07/temp/rt-polaritydata/rt-polarity.pos', 'r'\n",
    "        , encoding = 'latin-1') as temp_pos_file:\n",
    "    for row in temp_pos_file:\n",
    "        pos_data.append(row)\n",
    "\n",
    "neg_data = []\n",
    "with open('/home/admin-/PycharmProjects/TensorFlow-Machine-Learning-Cookbook/Chapter07/temp/rt-polaritydata/rt-polarity.neg', 'r'\n",
    "        , encoding = 'latin-1') as temp_neg_file:\n",
    "    for row in temp_neg_file:\n",
    "        neg_data.append(row)\n",
    "        \n",
    "texts = pos_data + neg_data\n",
    "target = [1]*len(pos_data) + [0]*len(neg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing Text Data\n"
     ]
    }
   ],
   "source": [
    "# Declare stop words\n",
    "stops = stopwords.words('english')\n",
    "\n",
    "# We pick a few test words for validation.\n",
    "valid_words = ['love', 'hate', 'happy', 'sad', 'man', 'woman']\n",
    "\n",
    "# Normalize text\n",
    "print('Normalizing Text Data')\n",
    "texts = text_helpers.normalize_text(texts, stops)\n",
    "\n",
    "# Texts must contain at least 3 words\n",
    "target = [target[ix] for ix, x in enumerate(texts) if len(x.split()) > window_size]\n",
    "texts = [x for x in texts if len(x.split()) > window_size]    \n",
    "assert(len(target)==len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Dictionary\n"
     ]
    }
   ],
   "source": [
    "# Build our data set and dictionaries\n",
    "print('Creating Dictionary')\n",
    "word_dictionary = text_helpers.build_dictionary(texts, vocabulary_size)\n",
    "word_dictionary_rev = dict(zip(word_dictionary.values(), word_dictionary.keys()))\n",
    "text_data = text_helpers.text_to_numbers(texts, word_dictionary)\n",
    "\n",
    "# Get validation word keys\n",
    "valid_examples = [word_dictionary[x] for x in valid_words]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n"
     ]
    }
   ],
   "source": [
    "print('Creating Model')\n",
    "# Define Embeddings:\n",
    "embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "doc_embeddings = tf.Variable(tf.random_uniform([len(texts), doc_embedding_size], -1.0, 1.0))\n",
    "# assert(len(target)==len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NCE loss parameters\n",
    "nce_weights = tf.Variable(tf.truncated_normal([vocabulary_size, concatenated_size],\n",
    "                                               stddev=1.0 / np.sqrt(concatenated_size)))\n",
    "nce_biases = tf.Variable(tf.zeros([vocabulary_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data/target placeholders\n",
    "x_inputs = tf.placeholder(tf.int32, shape=[None, window_size + 1]) # plus 1 for doc index\n",
    "y_target = tf.placeholder(tf.int32, shape=[None, 1])\n",
    "valid_dataset = tf.constant(valid_examples, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lookup the word embedding\n",
    "# Add together element embeddings in window:\n",
    "embed = tf.zeros([batch_size, embedding_size])\n",
    "for element in range(window_size):\n",
    "    embed += tf.nn.embedding_lookup(embeddings, x_inputs[:, element])\n",
    "\n",
    "# x_inputs                     =>  doc_indices\n",
    "# word, word, word  doc_id      doc_id\n",
    "# word, word, word  doc_id      doc_id\n",
    "# word, word, word  doc_id  =>  doc_id\n",
    "# word, word, word  doc_id      doc_id\n",
    "# word, word, word  doc_id      doc_id\n",
    "doc_indices = tf.slice(input_=x_inputs, begin=[0, window_size], size=[batch_size, 1])\n",
    "\n",
    "doc_embed = tf.nn.embedding_lookup(doc_embeddings, doc_indices)\n",
    "\n",
    "# concatenate embeddings\n",
    "final_embed = tf.concat([embed, tf.squeeze(doc_embed)], 1)\n",
    "# word_emb, word_emb, word_emb, doc_emb\n",
    "# word_emb, word_emb, word_emb, doc_emb\n",
    "# word_emb, word_emb, word_emb, doc_emb\n",
    "# word_emb, word_emb, word_emb, doc_emb\n",
    "# word_emb, word_emb, word_emb, doc_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get loss from prediction\n",
    "loss = tf.reduce_mean(tf.nn.nce_loss(nce_weights, nce_biases, y_target, final_embed,\n",
    "                                     num_sampled = num_sampled, num_classes = vocabulary_size))\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=model_learning_rate)\n",
    "train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-79-aa368afad2c1>:3: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\nInstructions for updating:\nkeep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarity between words\n",
    "# cosine similarity 를 이용하여 valid dataset의 similarity 구함\n",
    "norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), axis=1, keepdims=True))\n",
    "normalized_embeddings = embeddings / norm\n",
    "valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n",
    "similarity = tf.matmul(valid_embeddings, normalized_embeddings, transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/admin-/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\nInstructions for updating:\nUse `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# Create model saving operation\n",
    "saver = tf.train.Saver({\"embeddings\": embeddings, \"doc_embeddings\": doc_embeddings})\n",
    "\n",
    "#Add variable initializer.\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_data = []\n",
    "label_data = []\n",
    "sentences = text_data\n",
    "\n",
    "\n",
    "\n",
    "while len(batch_data) < batch_size:\n",
    "    rand_sentence_ix = int(np.random.choice(len(sentences), size=1))\n",
    "    rand_sentence = sentences[rand_sentence_ix]\n",
    "# rand_sentence = [59, 142, 2838, 0, 155, 222, 46, 171, 7335, 5]\n",
    "    # window_sequences = [rand_sentence[max((idx-window_size),0):(idx+window_size+1)] for idx, x in enumerate(rand_sentence)]\n",
    "    # window_sequences = [[59, 142, 2838, 0], [59, 142, 2838, 0, 155], [59, 142, 2838, 0, 155, 222], [59, 142, 2838, 0, 155, 222, 46], [142, 2838, 0, 155, 222, 46, 171], [2838, 0, 155, 222, 46, 171, 7335], [0, 155, 222, 46, 171, 7335, 5], [155, 222, 46, 171, 7335, 5], [222, 46, 171, 7335, 5], [46, 171, 7335, 5]]\n",
    "    # label_indices = [ix if ix<window_size else window_size for ix,x in enumerate(window_sequences)]\n",
    "    # method=='doc2vec':\n",
    "    # For doc2vec we keep LHS window only to predict target word\n",
    "    # batch_and_labels = [([59, 142, 2838], 0), ([142, 2838, 0], 155), ([2838, 0, 155], 222), ([0, 155, 222], 46), ([155, 222, 46], 171), ([222, 46, 171], 7335), ([46, 171, 7335], 5)]\n",
    "    batch_and_labels = [(rand_sentence[i:i+window_size], rand_sentence[i+window_size]) for i in range(0, len(rand_sentence)-window_size)]\n",
    "    batch, labels = [list(x) for x in zip(*batch_and_labels)]\n",
    "    batch = [x + [rand_sentence_ix] for x in batch]\n",
    "    \n",
    "    # Add document index to batch!! Remember that we must extract the last index in batch for the doc-index\n",
    "    batch_data.extend(batch[:batch_size])\n",
    "    label_data.extend(labels[:batch_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n"
     ]
    }
   ],
   "source": [
    "print('Creating Model')\n",
    "# Define Embeddings:\n",
    "embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "doc_embeddings = tf.Variable(tf.random_uniform([len(texts), doc_embedding_size], -1.0, 1.0))\n",
    "# assert(len(target)==len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_data = batch_data[:batch_size]\n",
    "label_data = label_data[:batch_size]\n",
    "\n",
    "# Convert to numpy array\n",
    "batch_data = np.array(batch_data)\n",
    "label_data = np.transpose(np.array([label_data]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 755],\n       [1132],\n       [2572],\n       [   3],\n       [  60],\n       [ 364],\n       [  55],\n       [   2],\n       [7033],\n       [ 364],\n       [ 631],\n       [ 198],\n       [   0],\n       [4701],\n       [   0],\n       [2443],\n       [ 961],\n       [  13],\n       [1072],\n       [  28],\n       [   0],\n       [1833],\n       [  51],\n       [  75],\n       [  33],\n       [1247],\n       [ 630],\n       [2904],\n       [ 467],\n       [5796],\n       [  23],\n       [2561],\n       [ 422],\n       [   3],\n       [ 340],\n       [   0],\n       [  22],\n       [  83],\n       [1239],\n       [2328],\n       [ 419],\n       [1940],\n       [ 206],\n       [ 783],\n       [1885],\n       [   0],\n       [2659],\n       [  74],\n       [5239],\n       [  41],\n       [   0],\n       [   2],\n       [   4],\n       [ 640],\n       [4892],\n       [4095],\n       [  51],\n       [4285],\n       [5212],\n       [ 168],\n       [   0],\n       [ 819],\n       [2456],\n       [ 192],\n       [   6],\n       [3141],\n       [  66],\n       [ 189],\n       [  23],\n       [ 118],\n       [   1],\n       [ 157],\n       [6878],\n       [   2],\n       [1029],\n       [5638],\n       [1051],\n       [6441],\n       [ 160],\n       [ 449],\n       [1106],\n       [ 849],\n       [1353],\n       [ 225],\n       [ 713],\n       [ 160],\n       [ 449],\n       [  11],\n       [ 899],\n       [ 392],\n       [  42],\n       [2456],\n       [ 192],\n       [   6],\n       [3141],\n       [  66],\n       [ 189],\n       [  23],\n       [ 118],\n       [   1],\n       [ 157],\n       [4760],\n       [3925],\n       [2314],\n       [5912],\n       [  91],\n       [ 319],\n       [1081],\n       [ 419],\n       [ 702],\n       [  76],\n       [  13],\n       [ 368],\n       [  24],\n       [   0],\n       [3282],\n       [ 600],\n       [2935],\n       [ 564],\n       [1075],\n       [3414],\n       [ 193],\n       [   0],\n       [  54],\n       [2354],\n       [ 725],\n       [  82],\n       [   0],\n       [ 107],\n       [  47],\n       [   0],\n       [   0],\n       [1040],\n       [  20],\n       [ 290],\n       [4199],\n       [3179],\n       [ 915],\n       [ 825],\n       [4013],\n       [ 278],\n       [2549],\n       [  77],\n       [1391],\n       [   0],\n       [3684],\n       [6855],\n       [   0],\n       [   6],\n       [5235],\n       [   0],\n       [ 123],\n       [   0],\n       [ 688],\n       [2459],\n       [ 154],\n       [ 172],\n       [   7],\n       [2087],\n       [ 115],\n       [ 131],\n       [ 780],\n       [ 867],\n       [3349],\n       [1970],\n       [4835],\n       [3902],\n       [ 220],\n       [  21],\n       [  61],\n       [  23],\n       [ 403],\n       [   9],\n       [6314],\n       [   0],\n       [  64],\n       [  37],\n       [ 139],\n       [   1],\n       [   0],\n       [1445],\n       [3984],\n       [ 157],\n       [   1],\n       [   0],\n       [ 909],\n       [ 130],\n       [  42],\n       [3326],\n       [4780],\n       [2379],\n       [1224],\n       [1741],\n       [ 194],\n       [ 950],\n       [   1],\n       [1601],\n       [1182],\n       [ 312],\n       [  18],\n       [ 163],\n       [  22],\n       [4747],\n       [   8],\n       [  48],\n       [  56],\n       [5128],\n       [ 268],\n       [ 716],\n       [ 308],\n       [ 873],\n       [   0],\n       [ 133],\n       [6326],\n       [1823],\n       [   8],\n       [ 461],\n       [  26],\n       [1544],\n       [  22],\n       [ 295],\n       [2518],\n       [  99],\n       [1916],\n       [ 871],\n       [ 878],\n       [4721],\n       [   0],\n       [1685],\n       [ 250],\n       [  61],\n       [   0],\n       [ 857],\n       [ 578],\n       [  24],\n       [2100],\n       [   0],\n       [1670],\n       [1920],\n       [   3],\n       [ 804],\n       [1303],\n       [7366],\n       [5631],\n       [  11],\n       [ 751],\n       [   0],\n       [2516],\n       [2687],\n       [2536],\n       [1510],\n       [3641],\n       [4586],\n       [ 170],\n       [3381],\n       [   0],\n       [ 306],\n       [   0],\n       [ 566],\n       [2519],\n       [ 628],\n       [2443],\n       [  84],\n       [ 818],\n       [  98],\n       [1060],\n       [1221],\n       [ 163],\n       [  67],\n       [2421],\n       [2421],\n       [2985],\n       [   0],\n       [ 108],\n       [  10],\n       [4719],\n       [ 122],\n       [2346],\n       [ 274],\n       [ 230],\n       [   0],\n       [ 934],\n       [ 164],\n       [  34],\n       [   0],\n       [   0],\n       [   4],\n       [   0],\n       [2990],\n       [   0],\n       [   0],\n       [ 469],\n       [ 125],\n       [  10],\n       [ 258],\n       [ 126],\n       [   6],\n       [ 100],\n       [ 292],\n       [  54],\n       [   0],\n       [   2],\n       [1042],\n       [6830],\n       [6831],\n       [3568],\n       [   0],\n       [  74],\n       [ 101],\n       [1104],\n       [1099],\n       [ 929],\n       [4523],\n       [2238],\n       [ 169],\n       [1416],\n       [ 366],\n       [1116],\n       [ 121],\n       [3885],\n       [ 366],\n       [ 281],\n       [2839],\n       [   3],\n       [  73],\n       [ 821],\n       [7432],\n       [ 671],\n       [2859],\n       [  14],\n       [  20],\n       [  22],\n       [1161],\n       [4530],\n       [   0],\n       [3622],\n       [1318],\n       [  18],\n       [ 185],\n       [ 549],\n       [ 163],\n       [ 849],\n       [ 872],\n       [  10],\n       [ 845],\n       [   0],\n       [ 533],\n       [   0],\n       [1089],\n       [ 931],\n       [2096],\n       [   0],\n       [4621],\n       [1172],\n       [   0],\n       [   0],\n       [5705],\n       [1887],\n       [4689],\n       [ 205],\n       [  10],\n       [ 124],\n       [3517],\n       [ 657],\n       [1312],\n       [ 107],\n       [6482],\n       [   0],\n       [ 552],\n       [5057],\n       [ 500],\n       [3975],\n       [ 114],\n       [ 784],\n       [ 987],\n       [   2],\n       [ 375],\n       [1390],\n       [  10],\n       [  48],\n       [   3],\n       [ 179],\n       [1366],\n       [ 522],\n       [2530],\n       [ 546],\n       [ 324],\n       [ 687],\n       [ 219],\n       [   4],\n       [ 331],\n       [  39],\n       [ 818],\n       [ 827],\n       [  19],\n       [ 104],\n       [3958],\n       [ 109],\n       [  46],\n       [ 790],\n       [ 103],\n       [ 866],\n       [ 299],\n       [   0],\n       [  87],\n       [ 237],\n       [2581],\n       [  91],\n       [3878],\n       [  26],\n       [2608],\n       [2059],\n       [4992],\n       [5192],\n       [1755],\n       [  12],\n       [   0],\n       [ 140],\n       [ 808],\n       [1750],\n       [ 106],\n       [1643],\n       [ 219],\n       [   4],\n       [  25],\n       [   0],\n       [ 563],\n       [5604],\n       [ 363],\n       [1843],\n       [1368],\n       [6859],\n       [   0],\n       [3687],\n       [   0],\n       [  99],\n       [ 181],\n       [1981],\n       [   0],\n       [1107],\n       [ 127],\n       [ 277],\n       [ 887],\n       [ 443],\n       [5218],\n       [ 769],\n       [6444],\n       [1924],\n       [  48],\n       [1620],\n       [ 322],\n       [ 993],\n       [   0],\n       [ 236],\n       [  35],\n       [   4],\n       [1638],\n       [   0],\n       [   2],\n       [   4],\n       [ 640],\n       [4892],\n       [   1],\n       [  61],\n       [ 335],\n       [3140],\n       [ 103],\n       [ 512],\n       [7034],\n       [   5],\n       [  38],\n       [  43],\n       [   7],\n       [ 659],\n       [ 134],\n       [ 511],\n       [   2],\n       [ 140],\n       [  18],\n       [ 793],\n       [ 627],\n       [ 307],\n       [ 106],\n       [  82],\n       [ 247],\n       [ 948],\n       [2626],\n       [1921],\n       [  11],\n       [2225],\n       [ 260],\n       [  85],\n       [1053],\n       [  46],\n       [  99],\n       [2849],\n       [   0],\n       [   0],\n       [  45],\n       [  14]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_data = batch_data[:batch_size]\n",
    "label_data = label_data[:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [x + [rand_sentence_ix] for x in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214],\n [2, 969, 369, 3214],\n [969, 369, 25, 3214],\n [369, 25, 264, 3214],\n [25, 264, 190, 3214],\n [264, 190, 17, 3214],\n [190, 17, 298, 3214],\n [721, 579, 110, 3214],\n [579, 110, 4793, 3214],\n [110, 4793, 39, 3214],\n [4793, 39, 2, 3214],\n [39, 2, 969, 3214]]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  59,  142, 2838,  757],\n       [ 142, 2838,    0,  757],\n       [2838,    0,  155,  757],\n       ...,\n       [  59,  142, 2838,  757],\n       [ 142, 2838,    0,  757],\n       [2838,    0,  155,  757]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 100 : 628.464599609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 200 : 636.0618896484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 300 : 597.6636962890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 400 : 620.3699951171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 500 : 540.2425537109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 600 : 559.2030029296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 700 : 579.6428833007812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 800 : 517.1127319335938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 900 : 543.0765380859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000 : 501.2564392089844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1100 : 459.6858825683594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1200 : 495.25726318359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1300 : 526.5216064453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1400 : 514.8302001953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1500 : 548.2741088867188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1600 : 497.1196594238281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1700 : 448.8726806640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1800 : 460.0523376464844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1900 : 463.58917236328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2000 : 443.3204040527344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2100 : 456.5766906738281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2200 : 412.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2300 : 413.76800537109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2400 : 423.2757263183594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2500 : 402.85107421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2600 : 437.022216796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2700 : 401.4002990722656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2800 : 434.47454833984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2900 : 434.8593444824219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 3000 : 400.12396240234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 3100 : 405.4183654785156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 3200 : 354.5293273925781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 3300 : 407.13201904296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 3400 : 370.84429931640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 3500 : 384.7926330566406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 3600 : 356.2498779296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 3700 : 396.0796203613281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 3800 : 362.3740539550781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 3900 : 367.8581848144531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 4000 : 353.00335693359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 4100 : 362.39697265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 4200 : 336.4878234863281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 4300 : 333.5133056640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 4400 : 354.57293701171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 4500 : 319.1820373535156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 4600 : 334.47955322265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 4700 : 331.5833740234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 4800 : 330.1589660644531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 4900 : 328.5409240722656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 5000 : 322.38055419921875\nNearest to love: forget, description, tunney, brainless, dire,\nNearest to hate: title, motions, transformed, cliché, avalanche,\nNearest to happy: comically, rabbitproof, derives, failure, weird,\nNearest to sad: clothes, estrogen, underestimated, viveka, nonthreatening,\nNearest to man: displaying, thousands, tattered, groundbreaking, nicole,\nNearest to woman: mopping, part, rather, old, receive,\nModel saved in file: /home/admin-/PycharmProjects/TensorFlow-Machine-Learning-Cookbook/Chapter07/Chapter07/temp/doc2vec_movie_embeddings.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 5100 : 343.4982604980469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 5200 : 331.7381286621094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 5300 : 339.3468933105469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 5400 : 306.4158630371094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 5500 : 332.0115661621094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 5600 : 308.5601806640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 5700 : 344.1044921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 5800 : 290.5260009765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 5900 : 310.0504455566406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 6000 : 296.4939880371094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 6100 : 292.824951171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 6200 : 321.4782409667969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 6300 : 301.31268310546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 6400 : 301.5829162597656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 6500 : 284.0710754394531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 6600 : 314.1914367675781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 6700 : 280.7607116699219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 6800 : 241.5409393310547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 6900 : 325.3104248046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 7000 : 286.5858154296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 7100 : 250.9484405517578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 7200 : 247.42613220214844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 7300 : 233.8578338623047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 7400 : 265.4263610839844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 7500 : 295.14605712890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 7600 : 273.1475524902344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 7700 : 289.41900634765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 7800 : 252.2401580810547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 7900 : 281.12249755859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 8000 : 252.943359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 8100 : 254.8169708251953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 8200 : 255.0115966796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 8300 : 200.64793395996094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 8400 : 278.91015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 8500 : 277.9523620605469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 8600 : 256.1515808105469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 8700 : 262.7819519042969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 8800 : 268.9782409667969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 8900 : 267.5743408203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 9000 : 272.08319091796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 9100 : 233.98269653320312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 9200 : 249.74514770507812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 9300 : 258.5440979003906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 9400 : 243.7466583251953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 9500 : 213.29258728027344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 9600 : 253.76669311523438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 9700 : 219.75958251953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 9800 : 243.5161590576172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 9900 : 213.06521606445312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 10000 : 217.2689971923828\nNearest to love: forget, description, tunney, showdown, amusing,\nNearest to hate: title, motions, transformed, cliché, avalanche,\nNearest to happy: comically, rabbitproof, derives, craig, fans,\nNearest to sad: clothes, estrogen, underestimated, nonthreatening, match,\nNearest to man: displaying, tattered, thousands, nicole, groundbreaking,\nNearest to woman: mopping, part, rather, old, receive,\nModel saved in file: /home/admin-/PycharmProjects/TensorFlow-Machine-Learning-Cookbook/Chapter07/Chapter07/temp/doc2vec_movie_embeddings.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 10100 : 254.18649291992188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 10200 : 244.3531494140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 10300 : 227.81527709960938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 10400 : 245.8350067138672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 10500 : 250.6411895751953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 10600 : 217.8228759765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 10700 : 207.69155883789062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 10800 : 208.3489227294922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 10900 : 225.92727661132812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 11000 : 208.95684814453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 11100 : 219.74388122558594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 11200 : 237.7339630126953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 11300 : 184.4294891357422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 11400 : 212.80703735351562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 11500 : 231.4120330810547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 11600 : 195.41778564453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 11700 : 207.54464721679688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 11800 : 174.81903076171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 11900 : 186.26902770996094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 12000 : 180.8069305419922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 12100 : 201.68568420410156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 12200 : 232.22134399414062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 12300 : 175.72084045410156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 12400 : 209.17843627929688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 12500 : 172.79771423339844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 12600 : 197.3273162841797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 12700 : 172.04052734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 12800 : 186.92303466796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 12900 : 154.44290161132812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 13000 : 202.25608825683594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 13100 : 192.99172973632812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 13200 : 185.81661987304688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 13300 : 183.77426147460938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 13400 : 197.1205291748047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 13500 : 183.49757385253906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 13600 : 163.53167724609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 13700 : 164.72535705566406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 13800 : 187.3488311767578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 13900 : 170.82948303222656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 14000 : 177.05441284179688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 14100 : 179.12677001953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 14200 : 167.47769165039062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 14300 : 185.6555633544922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 14400 : 149.68710327148438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 14500 : 175.5934600830078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 14600 : 153.7469482421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 14700 : 168.98468017578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 14800 : 141.44480895996094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 14900 : 152.24887084960938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 15000 : 189.54969787597656\nNearest to love: RARE, film, forget, amusing, tunney,\nNearest to hate: title, motions, transformed, cliché, scene,\nNearest to happy: comically, rabbitproof, derives, fans, craig,\nNearest to sad: clothes, estrogen, underestimated, nonthreatening, match,\nNearest to man: displaying, tattered, thousands, penetrating, nature,\nNearest to woman: mopping, part, rather, old, receive,\nModel saved in file: /home/admin-/PycharmProjects/TensorFlow-Machine-Learning-Cookbook/Chapter07/Chapter07/temp/doc2vec_movie_embeddings.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 15100 : 177.05377197265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 15200 : 169.88075256347656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 15300 : 173.31393432617188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 15400 : 196.9027557373047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 15500 : 157.96798706054688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 15600 : 181.78750610351562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 15700 : 173.39910888671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 15800 : 159.9265899658203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 15900 : 161.505126953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 16000 : 184.7455596923828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 16100 : 136.16140747070312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 16200 : 149.746337890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 16300 : 152.84178161621094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 16400 : 144.32571411132812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 16500 : 154.93809509277344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 16600 : 189.93576049804688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 16700 : 149.74656677246094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 16800 : 145.81756591796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 16900 : 140.8432159423828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 17000 : 156.0460662841797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 17100 : 129.29507446289062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 17200 : 155.56776428222656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 17300 : 134.3775634765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 17400 : 144.7186279296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 17500 : 160.2769317626953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 17600 : 144.099853515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 17700 : 157.66070556640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 17800 : 145.05104064941406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 17900 : 178.1148223876953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 18000 : 140.39015197753906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 18100 : 115.10545349121094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 18200 : 155.25169372558594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 18300 : 128.54156494140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 18400 : 139.80213928222656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 18500 : 159.45318603515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 18600 : 140.77658081054688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 18700 : 148.84774780273438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 18800 : 104.38582611083984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 18900 : 132.78543090820312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 19000 : 133.06509399414062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 19100 : 141.35928344726562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 19200 : 131.83201599121094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 19300 : 133.81576538085938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 19400 : 124.96187591552734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 19500 : 152.98765563964844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 19600 : 124.34127807617188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 19700 : 142.94821166992188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 19800 : 124.91018676757812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 19900 : 124.85443878173828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 20000 : 158.86346435546875\nNearest to love: RARE, film, forget, like, story,\nNearest to hate: title, motions, transformed, cliché, scene,\nNearest to happy: comically, rabbitproof, derives, fans, craig,\nNearest to sad: clothes, estrogen, underestimated, performances, match,\nNearest to man: displaying, tattered, nature, penetrating, thousands,\nNearest to woman: part, mopping, rather, old, receive,\nModel saved in file: /home/admin-/PycharmProjects/TensorFlow-Machine-Learning-Cookbook/Chapter07/Chapter07/temp/doc2vec_movie_embeddings.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 20100 : 130.78152465820312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 20200 : 112.71733093261719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 20300 : 119.89102935791016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 20400 : 124.56776428222656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 20500 : 124.5888671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 20600 : 98.18701934814453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 20700 : 124.46734619140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 20800 : 123.73479461669922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 20900 : 132.45298767089844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 21000 : 128.48641967773438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 21100 : 116.12315368652344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 21200 : 130.3195037841797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 21300 : 110.5950698852539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 21400 : 122.56068420410156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 21500 : 134.90341186523438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 21600 : 113.03409576416016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 21700 : 115.14320373535156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 21800 : 123.22954559326172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 21900 : 104.04108428955078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 22000 : 99.90912628173828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 22100 : 108.3569564819336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 22200 : 129.7957763671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 22300 : 104.19445037841797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 22400 : 126.40975952148438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 22500 : 102.25066375732422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 22600 : 109.38593292236328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 22700 : 122.40226745605469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 22800 : 100.41870880126953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 22900 : 141.4704132080078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 23000 : 114.3307876586914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 23100 : 96.2967529296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 23200 : 103.65885162353516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 23300 : 126.048095703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 23400 : 100.98416137695312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 23500 : 114.50312805175781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 23600 : 109.9110336303711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 23700 : 126.57734680175781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 23800 : 110.8818588256836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 23900 : 100.97348022460938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 24000 : 116.30828094482422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 24100 : 111.1719970703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 24200 : 89.21208190917969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 24300 : 100.21153259277344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 24400 : 102.12458801269531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 24500 : 115.54436492919922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 24600 : 88.57794952392578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 24700 : 100.83885955810547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 24800 : 82.06893157958984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 24900 : 101.99678802490234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 25000 : 92.41309356689453\nNearest to love: RARE, film, like, story, forget,\nNearest to hate: title, transformed, motions, scene, cliché,\nNearest to happy: comically, rabbitproof, derives, fans, craig,\nNearest to sad: clothes, estrogen, performances, underestimated, match,\nNearest to man: displaying, tattered, nature, director, trying,\nNearest to woman: part, rather, mopping, old, receive,\nModel saved in file: /home/admin-/PycharmProjects/TensorFlow-Machine-Learning-Cookbook/Chapter07/Chapter07/temp/doc2vec_movie_embeddings.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 25100 : 104.9809341430664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 25200 : 104.90501403808594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 25300 : 108.64646911621094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 25400 : 105.76583099365234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 25500 : 89.82581329345703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 25600 : 103.01800537109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 25700 : 90.14525604248047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 25800 : 96.89045715332031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 25900 : 100.02142333984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 26000 : 107.33386993408203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 26100 : 100.21453857421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 26200 : 86.7209243774414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 26300 : 84.14897155761719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 26400 : 88.57295989990234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 26500 : 97.72887420654297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 26600 : 77.43020629882812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 26700 : 114.18070220947266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 26800 : 78.54039764404297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 26900 : 111.30198669433594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 27000 : 77.13349151611328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 27100 : 84.27401733398438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 27200 : 84.54553985595703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 27300 : 106.50244903564453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 27400 : 83.88773345947266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 27500 : 85.87987518310547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 27600 : 104.13426971435547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 27700 : 93.49945068359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 27800 : 62.79829025268555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 27900 : 81.79812622070312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 28000 : 72.39286041259766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 28100 : 75.60943603515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 28200 : 67.39789581298828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 28300 : 79.52774810791016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 28400 : 85.44247436523438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 28500 : 99.79734802246094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 28600 : 78.04574584960938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 28700 : 101.23619079589844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 28800 : 84.0414047241211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 28900 : 64.49404907226562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 29000 : 96.96037292480469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 29100 : 79.15481567382812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 29200 : 72.79489135742188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 29300 : 92.94771575927734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 29400 : 75.40151977539062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 29500 : 100.85591125488281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 29600 : 76.90154266357422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 29700 : 90.20684051513672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 29800 : 71.85427856445312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 29900 : 68.57878875732422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 30000 : 90.04176330566406\nNearest to love: film, RARE, like, story, sense,\nNearest to hate: title, transformed, scene, motions, cliché,\nNearest to happy: comically, rabbitproof, derives, fans, craig,\nNearest to sad: clothes, performances, estrogen, underestimated, match,\nNearest to man: displaying, tattered, director, nature, without,\nNearest to woman: part, rather, old, mopping, receive,\nModel saved in file: /home/admin-/PycharmProjects/TensorFlow-Machine-Learning-Cookbook/Chapter07/Chapter07/temp/doc2vec_movie_embeddings.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 30100 : 83.49478912353516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 30200 : 73.1653060913086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 30300 : 96.88080596923828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 30400 : 66.07135009765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 30500 : 94.7668685913086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 30600 : 86.90435791015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 30700 : 83.50975036621094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 30800 : 80.8965072631836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 30900 : 80.57339477539062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 31000 : 67.65901184082031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 31100 : 87.59632873535156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 31200 : 65.43123626708984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 31300 : 85.41246032714844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 31400 : 55.96268844604492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 31500 : 75.02676391601562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 31600 : 65.26251983642578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 31700 : 81.72138977050781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 31800 : 86.45072174072266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 31900 : 75.21932983398438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 32000 : 69.80194091796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 32100 : 64.47361755371094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 32200 : 77.8928451538086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 32300 : 73.3518295288086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 32400 : 60.81438064575195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 32500 : 67.9982681274414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 32600 : 72.4134292602539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 32700 : 80.550048828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 32800 : 74.1961898803711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 32900 : 70.0536880493164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 33000 : 77.7694091796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 33100 : 91.49659729003906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 33200 : 86.6778564453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 33300 : 76.0452651977539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 33400 : 60.43057632446289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 33500 : 68.6065444946289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 33600 : 62.201656341552734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 33700 : 54.093299865722656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 33800 : 75.5601806640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 33900 : 79.40850067138672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 34000 : 78.19033813476562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 34100 : 81.19625091552734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 34200 : 80.5570297241211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 34300 : 70.80323791503906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 34400 : 60.61256790161133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 34500 : 64.24959564208984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 34600 : 66.29786682128906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 34700 : 69.20707702636719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 34800 : 61.29670715332031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 34900 : 62.03920364379883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 35000 : 76.17315673828125\nNearest to love: film, RARE, like, story, sense,\nNearest to hate: title, scene, transformed, motions, thriller,\nNearest to happy: comically, rabbitproof, fans, derives, craig,\nNearest to sad: performances, clothes, estrogen, underestimated, match,\nNearest to man: director, displaying, look, without, tattered,\nNearest to woman: part, rather, old, mopping, receive,\nModel saved in file: /home/admin-/PycharmProjects/TensorFlow-Machine-Learning-Cookbook/Chapter07/Chapter07/temp/doc2vec_movie_embeddings.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 35100 : 68.05036926269531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 35200 : 65.93144226074219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 35300 : 66.16565704345703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 35400 : 63.627098083496094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 35500 : 63.34417724609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 35600 : 65.09368133544922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 35700 : 71.17398071289062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 35800 : 58.2266731262207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 35900 : 58.6578254699707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 36000 : 61.08285140991211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 36100 : 64.703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 36200 : 55.871376037597656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 36300 : 55.66303253173828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 36400 : 63.81595230102539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 36500 : 63.13649368286133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 36600 : 68.11470031738281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 36700 : 71.55935668945312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 36800 : 65.05530548095703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 36900 : 70.46814727783203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 37000 : 67.79415893554688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 37100 : 58.44228744506836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 37200 : 73.06395721435547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 37300 : 55.647239685058594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 37400 : 72.42462158203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 37500 : 58.5876579284668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 37600 : 56.91773986816406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 37700 : 55.94434356689453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 37800 : 52.05949783325195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 37900 : 64.65779113769531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 38000 : 56.70231246948242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 38100 : 64.50885009765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 38200 : 52.735382080078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 38300 : 67.3477783203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 38400 : 56.126976013183594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 38500 : 52.74299240112305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 38600 : 58.25098419189453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 38700 : 71.71336364746094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 38800 : 55.265220642089844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 38900 : 60.56126403808594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 39000 : 53.65549850463867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 39100 : 57.411537170410156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 39200 : 57.43196105957031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 39300 : 59.23099899291992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 39400 : 59.308616638183594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 39500 : 56.50151824951172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 39600 : 49.64657974243164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 39700 : 60.60231018066406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 39800 : 52.12175369262695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 39900 : 52.322906494140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 40000 : 53.22346878051758\nNearest to love: film, RARE, like, story, sense,\nNearest to hate: title, scene, transformed, thriller, life,\nNearest to happy: comically, fans, rabbitproof, derives, craig,\nNearest to sad: performances, clothes, estrogen, underestimated, match,\nNearest to man: director, look, without, films, trying,\nNearest to woman: part, rather, old, mopping, receive,\nModel saved in file: /home/admin-/PycharmProjects/TensorFlow-Machine-Learning-Cookbook/Chapter07/Chapter07/temp/doc2vec_movie_embeddings.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 40100 : 53.7772331237793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 40200 : 43.333316802978516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 40300 : 60.254215240478516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 40400 : 57.26123046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 40500 : 49.83707046508789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 40600 : 53.28710174560547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 40700 : 58.9412841796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 40800 : 64.37770080566406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 40900 : 57.45044708251953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 41000 : 50.11730194091797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 41100 : 44.357540130615234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 41200 : 51.724212646484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 41300 : 60.6940803527832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 41400 : 61.41189956665039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 41500 : 55.570960998535156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 41600 : 44.852569580078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 41700 : 57.867244720458984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 41800 : 54.93391418457031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 41900 : 59.622859954833984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 42000 : 60.44733428955078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 42100 : 67.24003601074219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 42200 : 52.853641510009766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 42300 : 52.641151428222656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 42400 : 44.40454864501953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 42500 : 59.33860778808594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 42600 : 50.944881439208984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 42700 : 52.907291412353516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 42800 : 47.07518005371094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 42900 : 47.241275787353516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 43000 : 62.48678970336914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 43100 : 46.30942153930664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 43200 : 58.46253967285156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 43300 : 50.40556335449219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 43400 : 46.86590576171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 43500 : 48.13060760498047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 43600 : 52.83628845214844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 43700 : 54.38932800292969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 43800 : 47.429779052734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 43900 : 44.95607376098633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 44000 : 51.51152420043945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 44100 : 55.970516204833984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 44200 : 42.46107482910156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 44300 : 58.89589309692383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 44400 : 60.57653045654297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 44500 : 52.85725784301758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 44600 : 45.40605545043945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 44700 : 56.50881576538086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 44800 : 56.24419403076172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 44900 : 50.431007385253906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 45000 : 44.83063507080078\nNearest to love: film, RARE, like, story, sense,\nNearest to hate: title, scene, thriller, transformed, life,\nNearest to happy: comically, fans, rabbitproof, derives, craig,\nNearest to sad: performances, clothes, estrogen, underestimated, match,\nNearest to man: director, without, look, films, doesnt,\nNearest to woman: part, rather, old, mopping, receive,\nModel saved in file: /home/admin-/PycharmProjects/TensorFlow-Machine-Learning-Cookbook/Chapter07/Chapter07/temp/doc2vec_movie_embeddings.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 45100 : 53.80375671386719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 45200 : 43.858726501464844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 45300 : 43.62923812866211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 45400 : 52.72947692871094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 45500 : 57.82122039794922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 45600 : 45.42335510253906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 45700 : 54.180747985839844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 45800 : 51.648006439208984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 45900 : 48.68402099609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 46000 : 55.95798110961914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 46100 : 47.456974029541016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 46200 : 49.180294036865234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 46300 : 47.309654235839844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 46400 : 43.78919219970703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 46500 : 41.18227767944336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 46600 : 58.75706481933594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 46700 : 43.075618743896484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 46800 : 44.229530334472656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 46900 : 42.143951416015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 47000 : 44.713966369628906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 47100 : 51.991310119628906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 47200 : 46.74653244018555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 47300 : 50.68323516845703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 47400 : 47.75371551513672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 47500 : 49.97300720214844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 47600 : 50.52643585205078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 47700 : 46.44712448120117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 47800 : 38.8243408203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 47900 : 38.69496154785156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 48000 : 45.89588165283203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 48100 : 49.80282211303711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 48200 : 43.03294372558594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 48300 : 36.17827606201172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 48400 : 47.86823272705078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 48500 : 43.960391998291016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 48600 : 33.04789352416992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 48700 : 38.32299041748047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 48800 : 50.920570373535156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 48900 : 39.1376953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 49000 : 48.648014068603516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 49100 : 61.22666549682617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 49200 : 44.558773040771484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 49300 : 35.01939010620117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 49400 : 46.26719284057617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 49500 : 53.91652297973633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 49600 : 35.3145866394043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 49700 : 42.882667541503906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 49800 : 36.778602600097656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 49900 : 32.764427185058594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 50000 : 56.98976516723633\nNearest to love: film, RARE, like, story, sense,\nNearest to hate: title, scene, thriller, life, comedy,\nNearest to happy: comically, fans, rabbitproof, derives, craig,\nNearest to sad: performances, clothes, estrogen, underestimated, even,\nNearest to man: director, without, look, films, doesnt,\nNearest to woman: part, rather, old, mopping, receive,\nModel saved in file: /home/admin-/PycharmProjects/TensorFlow-Machine-Learning-Cookbook/Chapter07/Chapter07/temp/doc2vec_movie_embeddings.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 50100 : 43.54810333251953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 50200 : 42.4129524230957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 50300 : 41.446250915527344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 50400 : 51.25069046020508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 50500 : 49.58306884765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 50600 : 44.288047790527344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 50700 : 38.34211730957031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 50800 : 46.218509674072266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 50900 : 37.705726623535156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 51000 : 37.81064987182617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 51100 : 45.230892181396484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 51200 : 34.553382873535156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 51300 : 41.83440017700195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 51400 : 46.54860305786133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 51500 : 41.73790740966797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 51600 : 50.1498908996582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 51700 : 44.23688507080078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 51800 : 42.860382080078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 51900 : 44.81119918823242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 52000 : 41.606468200683594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 52100 : 42.02745056152344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 52200 : 31.134531021118164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 52300 : 55.678688049316406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 52400 : 41.067779541015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 52500 : 45.08087921142578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 52600 : 38.959774017333984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 52700 : 46.05098342895508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 52800 : 44.30498504638672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 52900 : 36.949710845947266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 53000 : 31.789884567260742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 53100 : 37.3970947265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 53200 : 44.48950958251953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 53300 : 38.96928024291992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 53400 : 44.05473709106445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 53500 : 46.04370880126953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 53600 : 34.2873420715332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 53700 : 29.470792770385742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 53800 : 32.52894592285156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 53900 : 39.15767288208008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 54000 : 42.60652160644531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 54100 : 32.0762825012207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 54200 : 36.08013916015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 54300 : 37.804412841796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 54400 : 32.132869720458984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 54500 : 37.17938232421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 54600 : 35.912078857421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 54700 : 37.64730453491211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 54800 : 42.884300231933594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 54900 : 44.90148162841797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 55000 : 35.1690788269043\nNearest to love: film, like, story, RARE, sense,\nNearest to hate: title, scene, thriller, life, comedy,\nNearest to happy: comically, fans, rabbitproof, derives, craig,\nNearest to sad: performances, clothes, even, estrogen, underestimated,\nNearest to man: director, without, look, films, doesnt,\nNearest to woman: part, rather, old, mopping, receive,\nModel saved in file: /home/admin-/PycharmProjects/TensorFlow-Machine-Learning-Cookbook/Chapter07/Chapter07/temp/doc2vec_movie_embeddings.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 55100 : 42.35094451904297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 55200 : 37.14287567138672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 55300 : 40.73284912109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 55400 : 30.51736831665039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 55500 : 43.0504150390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 55600 : 40.4708137512207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 55700 : 37.10354232788086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 55800 : 34.2625846862793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 55900 : 39.58885192871094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 56000 : 39.69356918334961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 56100 : 36.305564880371094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 56200 : 35.46942138671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 56300 : 36.39433288574219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 56400 : 35.88925552368164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 56500 : 35.80488204956055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 56600 : 31.315805435180664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 56700 : 36.7972526550293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 56800 : 44.50279998779297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 56900 : 41.97053527832031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 57000 : 40.396366119384766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 57100 : 29.195404052734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 57200 : 33.82234191894531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 57300 : 24.14838218688965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 57400 : 33.908329010009766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 57500 : 40.653099060058594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 57600 : 28.293621063232422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 57700 : 37.369300842285156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 57800 : 28.209074020385742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 57900 : 36.847808837890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 58000 : 34.07109069824219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 58100 : 30.19035530090332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 58200 : 42.841678619384766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 58300 : 43.21154022216797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 58400 : 35.79502868652344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 58500 : 34.701812744140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 58600 : 30.760374069213867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 58700 : 34.214271545410156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 58800 : 26.488407135009766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 58900 : 40.411277770996094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 59000 : 31.876571655273438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 59100 : 33.65525436401367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 59200 : 29.512928009033203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 59300 : 32.47008514404297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 59400 : 36.682395935058594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 59500 : 29.002758026123047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 59600 : 29.87746238708496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 59700 : 27.197616577148438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 59800 : 32.91647720336914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 59900 : 34.23596954345703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 60000 : 26.523347854614258\nNearest to love: film, like, story, sense, two,\nNearest to hate: title, scene, thriller, life, comedy,\nNearest to happy: comically, fans, rabbitproof, derives, craig,\nNearest to sad: performances, clothes, even, full, estrogen,\nNearest to man: director, without, look, films, doesnt,\nNearest to woman: part, rather, old, mopping, receive,\nModel saved in file: /home/admin-/PycharmProjects/TensorFlow-Machine-Learning-Cookbook/Chapter07/Chapter07/temp/doc2vec_movie_embeddings.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 60100 : 35.06768798828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 60200 : 27.72679328918457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 60300 : 30.15203094482422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 60400 : 33.93014144897461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 60500 : 31.521390914916992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 60600 : 33.40734100341797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 60700 : 36.02431106567383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 60800 : 30.78573226928711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 60900 : 26.456390380859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 61000 : 39.402374267578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 61100 : 35.51346206665039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 61200 : 32.338504791259766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 61300 : 30.98746109008789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 61400 : 32.62134552001953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 61500 : 34.958187103271484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 61600 : 29.863515853881836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 61700 : 26.947463989257812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 61800 : 32.901241302490234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 61900 : 32.35923385620117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 62000 : 38.78823471069336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 62100 : 30.20343017578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 62200 : 32.77943801879883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 62300 : 34.306640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 62400 : 38.15857696533203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 62500 : 30.550159454345703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 62600 : 34.42219543457031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 62700 : 30.482332229614258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 62800 : 36.487892150878906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 62900 : 32.283573150634766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 63000 : 33.21570587158203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 63100 : 38.68642044067383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 63200 : 24.269739151000977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 63300 : 28.944982528686523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 63400 : 30.16278648376465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 63500 : 35.80107116699219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 63600 : 32.01081085205078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 63700 : 29.46868324279785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 63800 : 31.1809024810791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 63900 : 39.4297981262207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 64000 : 29.511371612548828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 64100 : 36.27751159667969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 64200 : 31.871789932250977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 64300 : 32.78042221069336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 64400 : 29.336111068725586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 64500 : 34.672672271728516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 64600 : 33.561710357666016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 64700 : 33.42444610595703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 64800 : 31.365875244140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 64900 : 27.602336883544922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 65000 : 24.579139709472656\nNearest to love: film, like, story, sense, two,\nNearest to hate: title, scene, thriller, life, comedy,\nNearest to happy: comically, fans, rabbitproof, derives, craig,\nNearest to sad: performances, clothes, even, full, culture,\nNearest to man: director, without, look, films, doesnt,\nNearest to woman: part, rather, old, mopping, receive,\nModel saved in file: /home/admin-/PycharmProjects/TensorFlow-Machine-Learning-Cookbook/Chapter07/Chapter07/temp/doc2vec_movie_embeddings.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 65100 : 28.619598388671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 65200 : 36.55206298828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 65300 : 37.506439208984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 65400 : 30.086336135864258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 65500 : 32.718570709228516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 65600 : 27.54476547241211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 65700 : 35.40876388549805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 65800 : 29.350488662719727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 65900 : 25.740144729614258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 66000 : 28.519102096557617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 66100 : 25.502758026123047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 66200 : 30.816822052001953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 66300 : 33.54897689819336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 66400 : 35.22209548950195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 66500 : 30.40864372253418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 66600 : 28.189016342163086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 66700 : 26.80370330810547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 66800 : 28.156461715698242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 66900 : 25.9688663482666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 67000 : 30.199499130249023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 67100 : 30.071556091308594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 67200 : 28.974285125732422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 67300 : 28.724523544311523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 67400 : 28.407543182373047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 67500 : 32.67085266113281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 67600 : 30.101991653442383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 67700 : 24.454992294311523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 67800 : 33.796226501464844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 67900 : 29.941293716430664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 68000 : 26.211679458618164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 68100 : 39.4881706237793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 68200 : 32.69206619262695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 68300 : 30.905771255493164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 68400 : 30.55864143371582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 68500 : 31.209917068481445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 68600 : 23.64026641845703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 68700 : 26.951812744140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 68800 : 36.97422790527344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 68900 : 31.993242263793945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 69000 : 23.812042236328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 69100 : 25.131277084350586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 69200 : 27.543474197387695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 69300 : 34.44841384887695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 69400 : 27.42900276184082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 69500 : 29.257160186767578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 69600 : 29.553911209106445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 69700 : 24.255165100097656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 69800 : 28.904911041259766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 69900 : 32.828922271728516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 70000 : 28.147741317749023\nNearest to love: film, like, story, sense, two,\nNearest to hate: title, scene, thriller, life, comedy,\nNearest to happy: comically, fans, rabbitproof, derives, craig,\nNearest to sad: performances, clothes, even, full, culture,\nNearest to man: director, without, look, films, doesnt,\nNearest to woman: part, rather, old, mopping, receive,\nModel saved in file: /home/admin-/PycharmProjects/TensorFlow-Machine-Learning-Cookbook/Chapter07/Chapter07/temp/doc2vec_movie_embeddings.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 70100 : 24.737457275390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 70200 : 30.27182388305664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 70300 : 26.400997161865234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 70400 : 32.122615814208984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 70500 : 26.730731964111328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 70600 : 21.87307357788086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 70700 : 24.09294891357422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 70800 : 24.13055419921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 70900 : 28.887250900268555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 71000 : 25.917118072509766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 71100 : 27.59306526184082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 71200 : 23.437328338623047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 71300 : 25.937772750854492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 71400 : 31.178054809570312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 71500 : 26.32117462158203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 71600 : 25.380037307739258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 71700 : 28.429288864135742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 71800 : 23.931047439575195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 71900 : 24.597257614135742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 72000 : 28.731185913085938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 72100 : 24.17837905883789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 72200 : 26.575593948364258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 72300 : 27.30905532836914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 72400 : 30.058048248291016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 72500 : 21.55156135559082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 72600 : 28.52056884765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 72700 : 25.46991729736328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 72800 : 25.53067398071289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 72900 : 27.953187942504883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 73000 : 25.992904663085938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 73100 : 24.245542526245117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 73200 : 25.97600746154785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 73300 : 23.888805389404297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 73400 : 27.02769660949707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 73500 : 30.830095291137695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 73600 : 28.967729568481445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 73700 : 29.107656478881836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 73800 : 29.091157913208008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 73900 : 25.52780532836914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 74000 : 22.47437858581543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 74100 : 23.345401763916016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 74200 : 25.004817962646484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 74300 : 27.59181022644043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 74400 : 19.57280921936035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 74500 : 28.841800689697266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 74600 : 23.145156860351562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 74700 : 31.780149459838867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 74800 : 25.97103500366211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 74900 : 24.7315616607666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 75000 : 23.513843536376953\nNearest to love: film, like, sense, story, two,\nNearest to hate: title, scene, thriller, life, comedy,\nNearest to happy: comically, fans, rabbitproof, craig, derives,\nNearest to sad: performances, even, clothes, full, culture,\nNearest to man: director, without, look, films, find,\nNearest to woman: part, rather, old, mopping, receive,\nModel saved in file: /home/admin-/PycharmProjects/TensorFlow-Machine-Learning-Cookbook/Chapter07/Chapter07/temp/doc2vec_movie_embeddings.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 75100 : 27.64658546447754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 75200 : 24.8541316986084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 75300 : 26.080968856811523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 75400 : 28.441259384155273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 75500 : 26.994152069091797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 75600 : 19.978803634643555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 75700 : 28.43753433227539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 75800 : 30.764053344726562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 75900 : 26.404499053955078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 76000 : 23.98882484436035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 76100 : 24.526039123535156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 76200 : 34.2408447265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 76300 : 24.797754287719727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 76400 : 27.18068504333496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 76500 : 24.6887149810791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 76600 : 24.717090606689453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 76700 : 27.3472957611084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 76800 : 23.997879028320312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 76900 : 23.383445739746094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 77000 : 23.257617950439453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 77100 : 23.282163619995117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 77200 : 20.478504180908203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 77300 : 20.581941604614258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 77400 : 25.694242477416992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 77500 : 26.867340087890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 77600 : 27.64356803894043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 77700 : 22.6566219329834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 77800 : 22.39163589477539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 77900 : 26.90615463256836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 78000 : 24.785058975219727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 78100 : 24.46538734436035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 78200 : 26.106958389282227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 78300 : 23.632186889648438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 78400 : 26.498571395874023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 78500 : 23.34780502319336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 78600 : 23.042776107788086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 78700 : 26.183496475219727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 78800 : 31.862951278686523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 78900 : 28.258407592773438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 79000 : 23.082609176635742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 79100 : 21.77080726623535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 79200 : 22.100830078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 79300 : 30.57672119140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 79400 : 27.041704177856445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 79500 : 24.720460891723633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 79600 : 23.306379318237305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 79700 : 27.825666427612305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 79800 : 21.309736251831055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 79900 : 25.353118896484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 80000 : 28.205419540405273\nNearest to love: film, like, sense, story, two,\nNearest to hate: title, scene, thriller, life, comedy,\nNearest to happy: comically, fans, rabbitproof, craig, derives,\nNearest to sad: performances, even, clothes, full, culture,\nNearest to man: director, without, look, films, find,\nNearest to woman: part, rather, old, mopping, receive,\nModel saved in file: /home/admin-/PycharmProjects/TensorFlow-Machine-Learning-Cookbook/Chapter07/Chapter07/temp/doc2vec_movie_embeddings.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 80100 : 21.984498977661133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 80200 : 25.869834899902344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 80300 : 23.86876678466797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 80400 : 28.17156982421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 80500 : 22.318374633789062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 80600 : 23.31783676147461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 80700 : 25.026264190673828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 80800 : 28.142608642578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 80900 : 24.612972259521484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 81000 : 26.620695114135742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 81100 : 26.169591903686523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 81200 : 25.520429611206055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 81300 : 26.984617233276367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 81400 : 22.92101287841797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 81500 : 23.801603317260742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 81600 : 22.802743911743164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 81700 : 22.77347183227539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 81800 : 21.970394134521484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 81900 : 27.31851577758789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 82000 : 20.91360855102539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 82100 : 22.040407180786133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 82200 : 25.19942855834961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 82300 : 20.722211837768555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 82400 : 22.072114944458008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 82500 : 22.24267578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 82600 : 22.123931884765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 82700 : 24.154094696044922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 82800 : 28.472816467285156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 82900 : 23.51901626586914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 83000 : 23.971363067626953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 83100 : 17.91998863220215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 83200 : 26.96807861328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 83300 : 24.08873748779297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 83400 : 25.463987350463867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 83500 : 27.962459564208984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 83600 : 21.93434715270996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 83700 : 19.041597366333008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 83800 : 25.555217742919922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 83900 : 27.279720306396484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 84000 : 25.77469253540039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 84100 : 18.38838005065918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 84200 : 21.486331939697266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 84300 : 17.77606964111328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 84400 : 19.98447608947754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 84500 : 20.688968658447266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 84600 : 20.581972122192383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 84700 : 21.87368392944336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 84800 : 23.729936599731445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 84900 : 18.801965713500977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 85000 : 26.96297836303711\nNearest to love: film, like, sense, story, two,\nNearest to hate: title, scene, thriller, life, comedy,\nNearest to happy: fans, comically, rabbitproof, craig, isnt,\nNearest to sad: performances, even, clothes, full, culture,\nNearest to man: director, without, look, films, find,\nNearest to woman: part, rather, old, mopping, receive,\nModel saved in file: /home/admin-/PycharmProjects/TensorFlow-Machine-Learning-Cookbook/Chapter07/Chapter07/temp/doc2vec_movie_embeddings.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 85100 : 21.747257232666016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 85200 : 24.156429290771484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 85300 : 22.936416625976562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 85400 : 18.60137367248535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 85500 : 23.62541389465332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 85600 : 27.190977096557617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 85700 : 20.617467880249023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 85800 : 21.527246475219727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 85900 : 18.92986297607422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 86000 : 23.220937728881836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 86100 : 23.898269653320312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 86200 : 21.951156616210938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 86300 : 24.01337432861328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 86400 : 25.228134155273438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 86500 : 22.124725341796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 86600 : 25.77891731262207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 86700 : 22.78658676147461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 86800 : 20.147781372070312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 86900 : 19.030588150024414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 87000 : 17.636199951171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 87100 : 19.82411766052246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 87200 : 22.079891204833984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 87300 : 24.285186767578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 87400 : 22.936647415161133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 87500 : 21.22516441345215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 87600 : 23.695497512817383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 87700 : 18.650178909301758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 87800 : 19.761964797973633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 87900 : 20.31219482421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 88000 : 15.910723686218262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 88100 : 17.981985092163086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 88200 : 17.86916160583496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 88300 : 28.25072479248047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 88400 : 18.952404022216797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 88500 : 22.228059768676758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 88600 : 21.973527908325195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 88700 : 20.117053985595703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 88800 : 17.54192543029785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 88900 : 27.07697296142578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 89000 : 23.29404067993164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 89100 : 20.478515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 89200 : 24.373531341552734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 89300 : 17.125219345092773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 89400 : 24.637964248657227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 89500 : 20.866331100463867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 89600 : 16.57128143310547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 89700 : 20.209421157836914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 89800 : 20.59010887145996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 89900 : 19.646820068359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 90000 : 29.58647346496582\nNearest to love: film, like, sense, story, two,\nNearest to hate: title, scene, life, thriller, comedy,\nNearest to happy: fans, comically, rabbitproof, craig, isnt,\nNearest to sad: performances, even, clothes, full, culture,\nNearest to man: director, without, look, films, find,\nNearest to woman: part, rather, old, mopping, receive,\nModel saved in file: /home/admin-/PycharmProjects/TensorFlow-Machine-Learning-Cookbook/Chapter07/Chapter07/temp/doc2vec_movie_embeddings.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 90100 : 24.510108947753906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 90200 : 24.140167236328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 90300 : 22.33489418029785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 90400 : 20.794546127319336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 90500 : 17.08104705810547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 90600 : 18.38603973388672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 90700 : 20.606243133544922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 90800 : 19.889347076416016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 90900 : 20.23732566833496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 91000 : 22.185516357421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 91100 : 18.782424926757812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 91200 : 18.982786178588867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 91300 : 21.37263298034668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 91400 : 27.09800910949707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 91500 : 19.049570083618164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 91600 : 23.969308853149414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 91700 : 19.515512466430664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 91800 : 19.718652725219727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 91900 : 16.548343658447266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 92000 : 23.349590301513672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 92100 : 17.258682250976562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 92200 : 19.43953514099121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 92300 : 20.990856170654297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 92400 : 21.694562911987305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 92500 : 19.63930892944336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 92600 : 18.54724884033203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 92700 : 22.664487838745117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 92800 : 23.523250579833984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 92900 : 20.81964111328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 93000 : 20.957544326782227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 93100 : 23.569231033325195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 93200 : 22.270429611206055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 93300 : 21.296688079833984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 93400 : 24.475889205932617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 93500 : 21.998624801635742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 93600 : 24.3869571685791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 93700 : 20.10163688659668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 93800 : 19.2570858001709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 93900 : 23.802234649658203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 94000 : 19.655662536621094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 94100 : 19.73944091796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 94200 : 23.442293167114258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 94300 : 24.231632232666016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 94400 : 20.252338409423828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 94500 : 18.279752731323242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 94600 : 18.35975456237793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 94700 : 15.217652320861816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 94800 : 22.031869888305664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 94900 : 29.156387329101562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 95000 : 21.082874298095703\nNearest to love: film, like, sense, story, two,\nNearest to hate: title, scene, life, thriller, comedy,\nNearest to happy: fans, comically, rabbitproof, craig, isnt,\nNearest to sad: performances, even, full, clothes, culture,\nNearest to man: director, without, look, films, find,\nNearest to woman: part, rather, old, mopping, receive,\nModel saved in file: /home/admin-/PycharmProjects/TensorFlow-Machine-Learning-Cookbook/Chapter07/Chapter07/temp/doc2vec_movie_embeddings.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 95100 : 20.93621063232422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 95200 : 18.595340728759766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 95300 : 21.380796432495117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 95400 : 16.383699417114258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 95500 : 19.906843185424805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 95600 : 21.295753479003906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 95700 : 23.118783950805664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 95800 : 19.26276206970215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 95900 : 18.67102813720703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 96000 : 19.21463394165039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 96100 : 17.128936767578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 96200 : 23.115432739257812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 96300 : 19.473901748657227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 96400 : 23.485687255859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 96500 : 20.97248077392578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 96600 : 19.10995864868164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 96700 : 22.298667907714844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 96800 : 21.59014129638672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 96900 : 19.424739837646484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 97000 : 22.909303665161133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 97100 : 18.736968994140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 97200 : 20.1837100982666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 97300 : 19.27061653137207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 97400 : 20.495742797851562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 97500 : 17.86861801147461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 97600 : 23.170074462890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 97700 : 19.180654525756836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 97800 : 18.23340606689453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 97900 : 20.620695114135742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 98000 : 16.770797729492188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 98100 : 19.52475357055664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 98200 : 21.093156814575195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 98300 : 19.50722312927246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 98400 : 20.19526481628418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 98500 : 18.249168395996094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 98600 : 20.561233520507812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 98700 : 17.079055786132812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 98800 : 17.570785522460938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 98900 : 17.69552230834961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 99000 : 23.397123336791992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 99100 : 19.71784019470215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 99200 : 19.874446868896484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 99300 : 18.50421142578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 99400 : 18.403553009033203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 99500 : 19.62394142150879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 99600 : 20.016836166381836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 99700 : 19.872827529907227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 99800 : 20.01532745361328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 99900 : 18.31277084350586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 100000 : 19.431379318237305\nNearest to love: film, like, sense, story, two,\nNearest to hate: title, scene, life, thriller, comedy,\nNearest to happy: fans, comically, rabbitproof, craig, isnt,\nNearest to sad: performances, even, full, clothes, culture,\nNearest to man: director, without, look, films, find,\nNearest to woman: part, rather, old, mopping, receive,\nModel saved in file: /home/admin-/PycharmProjects/TensorFlow-Machine-Learning-Cookbook/Chapter07/Chapter07/temp/doc2vec_movie_embeddings.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Run the skip gram model.\n",
    "print('Starting Training')\n",
    "loss_vec = []\n",
    "loss_x_vec = []\n",
    "for i in range(generations):\n",
    "    batch_inputs, batch_labels = text_helpers.generate_batch_data(\n",
    "        text_data, batch_size, window_size, method='doc2vec')\n",
    "    \n",
    "    '''\n",
    "        x = [['i', 'am', 2],\n",
    "         ['am', 'sorry', 2],\n",
    "         ['sorry', 'but', 2],\n",
    "         ['but', 'i', 2],\n",
    "         ['i', 'love', 2],\n",
    "         ['love', 'you', 2],\n",
    "         ['you', '다', 2]]\n",
    "        // 여기서 2는 doc_id\n",
    "\n",
    "        y = ['sorry', 'but', 'i', 'love', 'you']\n",
    "    '''\n",
    "\n",
    "    feed_dict = {x_inputs : batch_inputs, y_target : batch_labels}\n",
    "\n",
    "    # Run the train step\n",
    "    sess.run(train_step, feed_dict=feed_dict)\n",
    "\n",
    "    # Return the loss\n",
    "    if (i+1) % print_loss_every == 0:\n",
    "        loss_val = sess.run(loss, feed_dict=feed_dict)\n",
    "        loss_vec.append(loss_val)\n",
    "        loss_x_vec.append(i+1)\n",
    "        print('Loss at step {} : {}'.format(i+1, loss_val))\n",
    "      \n",
    "    # Validation: Print some random words and top 5 related words\n",
    "    if (i+1) % print_valid_every == 0:\n",
    "        sim = sess.run(similarity, feed_dict=feed_dict)\n",
    "        for j in range(len(valid_words)):\n",
    "            valid_word = word_dictionary_rev[valid_examples[j]]\n",
    "            top_k = 5 # number of nearest neighbors\n",
    "            nearest = (-sim[j, :]).argsort()[1:top_k+1]\n",
    "            log_str = \"Nearest to {}:\".format(valid_word)\n",
    "            for k in range(top_k):\n",
    "                close_word = word_dictionary_rev[nearest[k]]\n",
    "                log_str = '{} {},'.format(log_str, close_word)\n",
    "            print(log_str)\n",
    "            \n",
    "    # Save dictionary + embeddings\n",
    "    if (i+1) % save_embeddings_every == 0:\n",
    "        # Save vocabulary dictionary\n",
    "        with open(os.path.join(data_folder_name,'movie_vocab.pkl'), 'wb') as f:\n",
    "            pickle.dump(word_dictionary, f)\n",
    "        \n",
    "        # Save embeddings\n",
    "        model_checkpoint_path = os.path.join(os.getcwd(),data_folder_name,'doc2vec_movie_embeddings.ckpt')\n",
    "        save_path = saver.save(sess, model_checkpoint_path)\n",
    "        print('Model saved in file: {}'.format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start logistic model-------------------------\n",
    "max_words = 20\n",
    "logistic_batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test sets\n",
    "# Need to keep the indices sorted to keep track of document index\n",
    "train_indices = np.sort(np.random.choice(len(target), round(0.8*len(target)), replace=False))\n",
    "test_indices = np.sort(np.array(list(set(range(len(target))) - set(train_indices))))\n",
    "texts_train = [x for ix, x in enumerate(texts) if ix in train_indices]\n",
    "texts_test = [x for ix, x in enumerate(texts) if ix in test_indices]\n",
    "target_train = np.array([x for ix, x in enumerate(target) if ix in train_indices])\n",
    "target_test = np.array([x for ix, x in enumerate(target) if ix in test_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert texts to lists of indices\n",
    "text_data_train = np.array(text_helpers.text_to_numbers(texts_train, word_dictionary))\n",
    "text_data_test = np.array(text_helpers.text_to_numbers(texts_test, word_dictionary))\n",
    "\n",
    "# Pad/crop movie reviews to specific length\n",
    "text_data_train = np.array([x[0:max_words] for x in [y+[0]*max_words for y in text_data_train]])\n",
    "text_data_test = np.array([x[0:max_words] for x in [y+[0]*max_words for y in text_data_test]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Logistic placeholders\n",
    "log_x_inputs = tf.placeholder(tf.int32, shape=[None, max_words + 1]) # plus 1 for doc index\n",
    "log_y_target = tf.placeholder(tf.int32, shape=[None, 1])\n",
    "\n",
    "# Define logistic embedding lookup (needed if we have two different batch sizes)\n",
    "# Add together element embeddings in window:\n",
    "log_embed = tf.zeros([logistic_batch_size, embedding_size])\n",
    "for element in range(max_words):\n",
    "    log_embed += tf.nn.embedding_lookup(embeddings, log_x_inputs[:, element])\n",
    "\n",
    "log_doc_indices = tf.slice(log_x_inputs, [0,max_words], [logistic_batch_size,1])\n",
    "log_doc_embed = tf.nn.embedding_lookup(doc_embeddings,log_doc_indices)\n",
    "\n",
    "# concatenate embeddings\n",
    "log_final_embed = tf.concat([log_embed, tf.squeeze(log_doc_embed)], 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model:\n",
    "# Create variables for logistic regression\n",
    "A = tf.Variable(tf.random_normal(shape=[concatenated_size,1]))\n",
    "b = tf.Variable(tf.random_normal(shape=[1,1]))\n",
    "\n",
    "# Declare logistic model (sigmoid in loss function)\n",
    "model_output = tf.add(tf.matmul(log_final_embed, A), b)\n",
    "\n",
    "# Declare loss function (Cross Entropy loss)\n",
    "logistic_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "    labels=tf.cast(log_y_target, tf.float32), logits = model_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual Prediction\n",
    "prediction = tf.round(tf.sigmoid(model_output))\n",
    "predictions_correct = tf.cast(tf.equal(prediction, tf.cast(log_y_target, tf.float32)), tf.float32)\n",
    "accuracy = tf.reduce_mean(predictions_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare optimizer\n",
    "logistic_opt = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "logistic_train_step = logistic_opt.minimize(logistic_loss, var_list=[A, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intitialize Variables\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Logistic Doc2Vec Model Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation # 500. Train Loss (Test Loss): 7.92 (7.89). Train Acc (Test Acc): 0.54 (0.51)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation # 1000. Train Loss (Test Loss): 9.58 (9.11). Train Acc (Test Acc): 0.52 (0.53)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation # 1500. Train Loss (Test Loss): 8.27 (10.21). Train Acc (Test Acc): 0.56 (0.52)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation # 2000. Train Loss (Test Loss): 9.08 (9.81). Train Acc (Test Acc): 0.56 (0.53)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation # 2500. Train Loss (Test Loss): 8.87 (8.94). Train Acc (Test Acc): 0.52 (0.52)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation # 3000. Train Loss (Test Loss): 8.71 (9.52). Train Acc (Test Acc): 0.53 (0.53)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation # 3500. Train Loss (Test Loss): 7.77 (8.59). Train Acc (Test Acc): 0.53 (0.50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation # 4000. Train Loss (Test Loss): 9.89 (9.83). Train Acc (Test Acc): 0.53 (0.56)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation # 4500. Train Loss (Test Loss): 8.23 (7.26). Train Acc (Test Acc): 0.50 (0.55)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation # 5000. Train Loss (Test Loss): 8.92 (9.43). Train Acc (Test Acc): 0.52 (0.54)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation # 5500. Train Loss (Test Loss): 7.76 (6.80). Train Acc (Test Acc): 0.51 (0.55)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation # 6000. Train Loss (Test Loss): 7.90 (8.85). Train Acc (Test Acc): 0.54 (0.52)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation # 6500. Train Loss (Test Loss): 8.98 (7.50). Train Acc (Test Acc): 0.50 (0.57)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation # 7000. Train Loss (Test Loss): 9.16 (9.32). Train Acc (Test Acc): 0.51 (0.54)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation # 7500. Train Loss (Test Loss): 8.12 (9.07). Train Acc (Test Acc): 0.56 (0.52)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation # 8000. Train Loss (Test Loss): 8.30 (9.28). Train Acc (Test Acc): 0.55 (0.49)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation # 8500. Train Loss (Test Loss): 8.37 (6.78). Train Acc (Test Acc): 0.52 (0.57)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation # 9000. Train Loss (Test Loss): 8.48 (8.82). Train Acc (Test Acc): 0.55 (0.50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation # 9500. Train Loss (Test Loss): 8.04 (8.51). Train Acc (Test Acc): 0.56 (0.52)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation # 10000. Train Loss (Test Loss): 8.87 (9.34). Train Acc (Test Acc): 0.55 (0.51)\n"
     ]
    }
   ],
   "source": [
    "# Start Logistic Regression\n",
    "print('Starting Logistic Doc2Vec Model Training')\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "i_data = []\n",
    "for i in range(10000):\n",
    "    rand_index = np.random.choice(text_data_train.shape[0], size=logistic_batch_size)\n",
    "    rand_x = text_data_train[rand_index]\n",
    "    # Append review index at the end of text data\n",
    "    rand_x_doc_indices = train_indices[rand_index]\n",
    "    rand_x = np.hstack((rand_x, np.transpose([rand_x_doc_indices])))\n",
    "    rand_y = np.transpose([target_train[rand_index]])\n",
    "    \n",
    "    feed_dict = {log_x_inputs: rand_x, log_y_target: rand_y}\n",
    "    sess.run(logistic_train_step, feed_dict=feed_dict)\n",
    "    \n",
    "    # Only record loss and accuracy every 100 generations\n",
    "    if (i+1)%100==0:\n",
    "        rand_index_test = np.random.choice(text_data_test.shape[0], size=logistic_batch_size)\n",
    "        rand_x_test = text_data_test[rand_index_test]\n",
    "        # Append review index at the end of text data\n",
    "        rand_x_doc_indices_test = test_indices[rand_index_test]\n",
    "        rand_x_test = np.hstack((rand_x_test, np.transpose([rand_x_doc_indices_test])))\n",
    "        rand_y_test = np.transpose([target_test[rand_index_test]])\n",
    "        \n",
    "        test_feed_dict = {log_x_inputs: rand_x_test, log_y_target: rand_y_test}\n",
    "        \n",
    "        i_data.append(i+1)\n",
    "\n",
    "        train_loss_temp = sess.run(logistic_loss, feed_dict=feed_dict)\n",
    "        train_loss.append(train_loss_temp)\n",
    "        \n",
    "        test_loss_temp = sess.run(logistic_loss, feed_dict=test_feed_dict)\n",
    "        test_loss.append(test_loss_temp)\n",
    "        \n",
    "        train_acc_temp = sess.run(accuracy, feed_dict=feed_dict)\n",
    "        train_acc.append(train_acc_temp)\n",
    "    \n",
    "        test_acc_temp = sess.run(accuracy, feed_dict=test_feed_dict)\n",
    "        test_acc.append(test_acc_temp)\n",
    "    if (i+1)%500==0:\n",
    "        acc_and_loss = [i+1, train_loss_temp, test_loss_temp, train_acc_temp, test_acc_temp]\n",
    "        acc_and_loss = [np.round(x,2) for x in acc_and_loss]\n",
    "        print('Generation # {}. Train Loss (Test Loss): {:.2f} ({:.2f}). Train Acc (Test Acc): {:.2f} ({:.2f})'.format(*acc_and_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss over time\n",
    "plt.plot(i_data, train_loss, 'k-', label='Train Loss')\n",
    "plt.plot(i_data, test_loss, 'r--', label='Test Loss', linewidth=2)\n",
    "plt.title('Cross Entropy Loss per Generation')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Plot train and test accuracy\n",
    "plt.plot(i_data, train_acc, 'k-', label='Train Set Accuracy')\n",
    "plt.plot(i_data, test_acc, 'r--', label='Test Set Accuracy', linewidth=2)\n",
    "plt.title('Train and Test Accuracy')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
